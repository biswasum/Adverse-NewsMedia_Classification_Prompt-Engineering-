{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "46697e41-3c58-43d1-ad9a-56611f2b92b4",
                "id": "zJLtsQobpd0R"
            },
            "source": [
                "<center>\n",
                "<h1><b>Classification tasks with Azure Open AI</b>\n",
                "</center>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "1f06d5cb-8efe-4827-a6c1-116f47da68a0",
                "id": "w_lddF6ADKJ5"
            },
            "source": [
                "# Introduction\n",
                "\n",
                "Welcome! In this section , we are going to look into the Adverse News Media Analysis for B2B segments The financial ratings of a company are impacted by adverse news media coverage. This lead to negative sentiments and affect the company's financial ratings \n",
                "\n",
                "**Task 1: Auto-Labelling System**\n",
                "\n",
                "Initially, our focus is on categories with the highest incidence of mislabeling. Currently, we are facing  mislabeling in the system. The automated News Media Sentiment classifier system will significantly reduce the time and effort required to source and analyze adverse news media daily. This will enable the company to respond quickly to negative news and take appropriate action to mitigate the impact on investor and modify or downgrade ratings of company\n",
                "1. Positive\n",
                "2. Negative"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "292af8f8-a88a-45b9-907d-2065206c63e0",
                "id": "foi0sYHaQm1A"
            },
            "source": [
                "Let's start by setting up our code environment."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "472ada41-68f8-4d1a-ac2a-5cc3860e9016",
                "id": "0zTC8qPRPahk"
            },
            "source": [
                "## Setup"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "58a25803-bad2-46e7-bcd1-a2806e596c36",
                "id": "ykLYC3zzSr8z"
            },
            "source": [
                "## Installation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "fa4ca472-bdd1-43d9-aa66-16a4912370d2",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "9b23OfNvStm-",
                "language": "sql",
                "outputId": "f646b324-f132-4cbf-9fbc-8a3da6ca9e9f",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [],
            "source": [
                "!pip install openai==1.2.0 tiktoken datasets session-info --quiet"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "ccaac3ac-4c1a-4241-96f4-78230a73ef17",
                "id": "YFZj9kr8Pahl"
            },
            "source": [
                "## Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {
                "azdata_cell_guid": "19abc341-6763-4ca2-87bc-779ccaa64c89",
                "id": "Q3gwxSqQPahl",
                "language": "sql",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [],
            "source": [
                "# Import all Python packages required to access the Azure Open AI API.\n",
                "# Import additional packages required to access datasets and create examples.\n",
                "\n",
                "import json\n",
                "import random\n",
                "import tiktoken\n",
                "import session_info\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "from openai import AzureOpenAI\n",
                "\n",
                "from datasets import load_dataset\n",
                "from collections import Counter\n",
                "from tqdm import tqdm\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import accuracy_score"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "1c96ad8e-9e90-43ca-8a08-4f08f9a7ad2d",
                "id": "SN0wIDUjPahn"
            },
            "source": [
                "## Authentication"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {
                "azdata_cell_guid": "60a00636-b120-4946-9028-81e2d5d339b2",
                "id": "cxLhZIviPahn",
                "language": "sql",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [],
            "source": [
                "with open('config.json', 'r') as az_creds:\n",
                "    data = az_creds.read()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {
                "azdata_cell_guid": "0fe596cc-56d4-462e-bc74-a6b9a14a70d5",
                "id": "nL9GpBEVPahn",
                "language": "sql",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [],
            "source": [
                "creds = json.loads(data)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {
                "azdata_cell_guid": "87ea8a51-4ab5-4544-9018-147ec514af7c",
                "id": "pSaJqJC0YyDK",
                "language": "sql",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [],
            "source": [
                "client = AzureOpenAI(\n",
                "    azure_endpoint=creds[\"AZURE_OPENAI_ENDPOINT\"],\n",
                "    api_key=creds[\"AZURE_OPENAI_KEY\"],\n",
                "    api_version=creds[\"AZURE_OPENAI_APIVERSION\"]\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {
                "azdata_cell_guid": "4cf4ee39-46b2-4c6d-a714-b34617d2fcaa",
                "id": "Atf3l2mNPahp",
                "language": "sql",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [],
            "source": [
                "deployment_name = creds[\"CHATGPT_MODEL\"]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "8add4188-246f-4e95-a347-d81ae9771004",
                "id": "HQpkd5elTMhd"
            },
            "source": [
                "## Utilities"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "f13674cc-d3d4-481b-839d-8b247a3782ef",
                "id": "QZixg_xITN8s"
            },
            "source": [
                "While developing the solution, we need to be mindful of the costs it will incurr for the business. Even a good solution that comes at a high cost is not useful for the business. For LLMs, costs are associated with the number of tokens consumed. Let's create a function using tiktoken to understand the number of tokens we are using in each of out prompts. This information will be cruicial while deciding the final technique we are going to use to solve the problem."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {
                "azdata_cell_guid": "51b8ca67-198c-4df2-89e5-2a2a3e873e5d",
                "id": "V5Gp-_CxPahp",
                "language": "sql",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [],
            "source": [
                "def num_tokens_from_messages(messages):\n",
                "\n",
                "    \"\"\"\n",
                "    Return the number of tokens used by a list of messages.\n",
                "    Adapted from the Open AI cookbook token counter\n",
                "    \"\"\"\n",
                "\n",
                "    encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
                "\n",
                "    # Each message is sandwiched with <|start|>role and <|end|>\n",
                "    # Hence, messages look like: <|start|>system or user or assistant{message}<|end|>\n",
                "\n",
                "    tokens_per_message = 3 # token1:<|start|>, token2:system(or user or assistant), token3:<|end|>\n",
                "\n",
                "    num_tokens = 0\n",
                "\n",
                "    for message in messages:\n",
                "        num_tokens += tokens_per_message\n",
                "        for key, value in message.items():\n",
                "            num_tokens += len(encoding.encode(value))\n",
                "\n",
                "    num_tokens += 3  # every reply is primed with <|start|>assistant<|message|>\n",
                "\n",
                "    return num_tokens"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "b6609039-a30d-48a0-af11-d7ff1ca5998d",
                "id": "3sP7s5TDPahq"
            },
            "source": [
                "## Task 1: Auto-Label Classificaation"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "9de7b926-8f60-4f68-969a-777d8c22bb11",
                "id": "4NkdNjY3DdgD"
            },
            "source": [
                "Let's have a look at the data and get a feel of it."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "2e20f2f5-50c3-40fc-84b0-d9b35b1d349e",
                "id": "wH4wcUNaR83t"
            },
            "source": [
                "### Preparing Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {
                "azdata_cell_guid": "e8acf6d8-9f76-4f5b-90a3-dd2c80548e55",
                "id": "qzvme58ISAk6",
                "language": "sql",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [],
            "source": [
                "data = pd.read_csv(r'C:\\Users\\BISWA\\Documents\\BDM\\GL\\Week9\\newsmedia_consolidated_file.csv',encoding=\"cp1252\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {
                "azdata_cell_guid": "daa7c3e3-3770-4aa1-8f15-08fb38b371ff",
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 363
                },
                "id": "oeSQHKNkVoiC",
                "language": "sql",
                "outputId": "f3d0bb44-628a-4c32-b622-c1c1cb550d4a",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Headline</th>\n",
                            "      <th>Category</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>Jio Financial Services gets RBI nod to become ...</td>\n",
                            "      <td>NEGATIVE</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>No objection to release of engines to lessors:...</td>\n",
                            "      <td>POSITIVE</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>Kesorams cement business demerger may be compl...</td>\n",
                            "      <td>NEGATIVE</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>Dispute at Bandhan Employees Welfare Trust grows</td>\n",
                            "      <td>NEGATIVE</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>Welspun One raises Rs 2,275 cr for second fund...</td>\n",
                            "      <td>NEGATIVE</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>5</th>\n",
                            "      <td>Nykaa sees 1.47 crore shares exchanged in bloc...</td>\n",
                            "      <td>NEGATIVE</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>6</th>\n",
                            "      <td>Billionaire Gautam Adani now wants to build...</td>\n",
                            "      <td>NEGATIVE</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>7</th>\n",
                            "      <td>Eicher, BHEL, and more: Kotak flags overvalued...</td>\n",
                            "      <td>POSITIVE</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>8</th>\n",
                            "      <td>Kotak evaluating if Kingdon deliberately misle...</td>\n",
                            "      <td>POSITIVE</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>9</th>\n",
                            "      <td>Hindenburg shared Adani report with client 2 m...</td>\n",
                            "      <td>POSITIVE</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                            Headline  Category\n",
                            "0  Jio Financial Services gets RBI nod to become ...  NEGATIVE\n",
                            "1  No objection to release of engines to lessors:...  POSITIVE\n",
                            "2  Kesorams cement business demerger may be compl...  NEGATIVE\n",
                            "3   Dispute at Bandhan Employees Welfare Trust grows  NEGATIVE\n",
                            "4  Welspun One raises Rs 2,275 cr for second fund...  NEGATIVE\n",
                            "5  Nykaa sees 1.47 crore shares exchanged in bloc...  NEGATIVE\n",
                            "6     Billionaire Gautam Adani now wants to build...  NEGATIVE\n",
                            "7  Eicher, BHEL, and more: Kotak flags overvalued...  POSITIVE\n",
                            "8  Kotak evaluating if Kingdon deliberately misle...  POSITIVE\n",
                            "9  Hindenburg shared Adani report with client 2 m...  POSITIVE"
                        ]
                    },
                    "execution_count": 19,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "data.head(10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {
                "azdata_cell_guid": "730e850b-10a2-480d-8197-0632610e749e",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "Gd7GgpUt9AE4",
                "language": "sql",
                "outputId": "c3842305-71cb-4e1f-dd7a-afbbd6b9ae5c",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "Category\n",
                            "POSITIVE    672\n",
                            "NEGATIVE    194\n",
                            "Name: count, dtype: int64"
                        ]
                    },
                    "execution_count": 20,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "data.Category.value_counts()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "d27a3971-231c-426e-90f0-f60c3089df1c",
                "id": "pnwTt-Jt3pp5"
            },
            "source": [
                "Note how the dataset is evenly balanced with equal number of reviews assembled for each of the category. This makes our life easy."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "f8bab93f-e9c9-4a46-a2df-96c753ee1f6f",
                "id": "hPHHq5_fImow"
            },
            "source": [
                "Since this is a classification exercise with a balanced dataset, we can use accuracy as our metric. We need to also be mindful of the tokens consumed for each prompt as this is going to be a perpetual task for the business as new products are added everyday."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "660aa5aa-0721-483d-bfbb-685e8189d3ad",
                "id": "Y8uqAOkAJEOt"
            },
            "source": [
                "#### Test and Train Split"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "aa6021ca-f2be-4511-a00c-c41587ead681",
                "id": "NoDGl2mc4UrU"
            },
            "source": [
                "Let us split the data into two segments - one segment that gives us a pool to draw few-shot examples from and another segment that gives us a pool of gold examples which will be used for testing."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "eebe3b93-0e02-4be4-b21f-ca7ce969b275",
                "id": "uOOoD0Skm8d2"
            },
            "source": [
                "In summary, we extract a dataset from a corpus by processing required fields. Each example should contain the text input and an annotated label. Once we create examples and gold examples from this dataset, this curated dataset is stored in a format appropriate for reuse (e.g., JSON)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "3e04fcde-82ad-4bed-be0e-39c56885cd02",
                "id": "2ExVGFPl4tdx"
            },
            "source": [
                "To select gold examples for this session, we sample randomly from the test data using a `random_state=42`. This ensures that the examples from multiple runs of the sampling are the same (i.e., they are randomly selected but do not change between different runs of the notebook). Note that we are doing this only to keep execution times low for illustration. In practise, large number of gold examples facilitate robust estimates of model accuracy."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {
                "azdata_cell_guid": "695bcaf6-3507-4309-bdf0-28bd5b5c1a97",
                "id": "dkXtXbc9N5rC",
                "language": "sql",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [],
            "source": [
                "examples_df, gold_examples_df = train_test_split(\n",
                "    data, #<- the full dataset\n",
                "    test_size=0.8, #<- 80% random sample selected for gold examples\n",
                "    random_state=42, #<- ensures that the splits are the same for every session\n",
                "    stratify=data['Category'] #<- ensures equal distribution of labels\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 88,
            "metadata": {
                "azdata_cell_guid": "531cd4f4-2875-41f6-b612-38917c0b9a58",
                "id": "UpeZL2989746",
                "language": "sql",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [],
            "source": [
                "gold_examples = (\n",
                "        gold_examples_df.to_json(orient='records')\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 89,
            "metadata": {
                "azdata_cell_guid": "8e14cc8e-53df-4b51-ad68-8140720cd322",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "bGSj2dfZOMW-",
                "language": "sql",
                "outputId": "a03932bd-7222-4a0d-a991-9bb3ea1b6004",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "((173, 2), (693, 2))"
                        ]
                    },
                    "execution_count": 89,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "(examples_df.shape, gold_examples_df.shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 90,
            "metadata": {
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Headline</th>\n",
                            "      <th>Category</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>168</th>\n",
                            "      <td>Top 10 happiest countries in the world for ...</td>\n",
                            "      <td>NEGATIVE</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>394</th>\n",
                            "      <td>Singapore container ship logjam spills over to...</td>\n",
                            "      <td>POSITIVE</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>228</th>\n",
                            "      <td>NEET UG 2024 Hearing Live Updates: Supreme Cou...</td>\n",
                            "      <td>POSITIVE</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>141</th>\n",
                            "      <td>How Xi Jinping can surprise world with big-...</td>\n",
                            "      <td>POSITIVE</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>707</th>\n",
                            "      <td>Anand Mahindra: It’s no longer the Queen’s ...</td>\n",
                            "      <td>POSITIVE</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>30</th>\n",
                            "      <td>To every person who suffered ... : Govt dec...</td>\n",
                            "      <td>POSITIVE</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>118</th>\n",
                            "      <td>Captain Anshuman Singh’s parents want Armys...</td>\n",
                            "      <td>POSITIVE</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>21</th>\n",
                            "      <td>John Hunt: British police arrest man on sus...</td>\n",
                            "      <td>POSITIVE</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>575</th>\n",
                            "      <td>Forces will carry out its mission: Kim Jong...</td>\n",
                            "      <td>POSITIVE</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>860</th>\n",
                            "      <td>Chandrashekar Ghosh may step down from Bandhan...</td>\n",
                            "      <td>POSITIVE</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>693 rows × 2 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                              Headline  Category\n",
                            "168     Top 10 happiest countries in the world for ...  NEGATIVE\n",
                            "394  Singapore container ship logjam spills over to...  POSITIVE\n",
                            "228  NEET UG 2024 Hearing Live Updates: Supreme Cou...  POSITIVE\n",
                            "141     How Xi Jinping can surprise world with big-...  POSITIVE\n",
                            "707     Anand Mahindra: It’s no longer the Queen’s ...  POSITIVE\n",
                            "..                                                 ...       ...\n",
                            "30      To every person who suffered ... : Govt dec...  POSITIVE\n",
                            "118     Captain Anshuman Singh’s parents want Armys...  POSITIVE\n",
                            "21      John Hunt: British police arrest man on sus...  POSITIVE\n",
                            "575     Forces will carry out its mission: Kim Jong...  POSITIVE\n",
                            "860  Chandrashekar Ghosh may step down from Bandhan...  POSITIVE\n",
                            "\n",
                            "[693 rows x 2 columns]"
                        ]
                    },
                    "execution_count": 90,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "gold_examples_df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 91,
            "metadata": {
                "azdata_cell_guid": "643c19d6-c5c3-4230-b855-98c1cd9d3bfe",
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 143
                },
                "id": "r8J58KMMM95s",
                "language": "sql",
                "outputId": "dca725f6-a267-46fa-8424-11fb2bccaa0a",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Headline</th>\n",
                            "      <th>Category</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>168</th>\n",
                            "      <td>Top 10 happiest countries in the world for ...</td>\n",
                            "      <td>NEGATIVE</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>394</th>\n",
                            "      <td>Singapore container ship logjam spills over to...</td>\n",
                            "      <td>POSITIVE</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>228</th>\n",
                            "      <td>NEET UG 2024 Hearing Live Updates: Supreme Cou...</td>\n",
                            "      <td>POSITIVE</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                              Headline  Category\n",
                            "168     Top 10 happiest countries in the world for ...  NEGATIVE\n",
                            "394  Singapore container ship logjam spills over to...  POSITIVE\n",
                            "228  NEET UG 2024 Hearing Live Updates: Supreme Cou...  POSITIVE"
                        ]
                    },
                    "execution_count": 91,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "gold_examples_df.head(3)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "0c44d999-29b1-4b0b-bbf2-392a174b1023",
                "id": "RHcvbwDcJKZF"
            },
            "source": [
                "With everything setup, let's start working on our prompts."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "960b2769-cb87-442a-a4ab-7c00e9b19328",
                "id": "ZPsU-h8FPaht"
            },
            "source": [
                "### Step 3: Derive Prompt"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "720fa836-b9e7-483f-b14d-390b3516991b",
                "id": "X3uS8NWfNqBG"
            },
            "source": [
                "#### Create prompts"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 92,
            "metadata": {
                "azdata_cell_guid": "1b227a3a-e039-47fc-b522-53130399e74a",
                "id": "NfDUKbCgPahu",
                "language": "sql",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [],
            "source": [
                "user_message_template = \"\"\"```{headline}```\"\"\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "db8beff3-c1a1-4cde-9f38-bd936f6ed23c",
                "id": "Sxwq7qwrwLwn"
            },
            "source": [
                "Let's create a zero-shot prompt for this scenario. We need to make sure that LLM outputs only the category label and not explanation. So, let's add explicit instructions for that."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "0fa669a6-9f11-4687-b5e5-a2a1195db131",
                "id": "w8RoXc0qJW0l"
            },
            "source": [
                "**Prompt 1: Zero-shot**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 107,
            "metadata": {
                "azdata_cell_guid": "a3d637bd-6efd-4bf0-9e31-543006874098",
                "id": "J79_IaxHJdY2",
                "language": "sql",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [],
            "source": [
                "zero_shot_system_message = \"\"\"\n",
                "Classify the following News Media headlines presented in the input into one of the following categories uisng BERT sentiment classifier for submitting \n",
                "news headline.\n",
                "Categories - ['Positive', 'Negative']\n",
                "News description will be delimited by triple backticks in the input.\n",
                "Answer only 'Positive' or 'Negative'. Nothing Else. Do not explain your answer.\n",
                "\"\"\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 108,
            "metadata": {
                "azdata_cell_guid": "fb563136-b073-4b11-84e7-fe344b22ff8b",
                "id": "t8cjNjiJJpzc",
                "language": "sql",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [],
            "source": [
                "zero_shot_prompt = [{'role':'system', 'content': zero_shot_system_message}]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "a32955b9-b24d-4d15-84d9-ec63d96c993a",
                "id": "viKiMpevxVbC"
            },
            "source": [
                "Let's check the number of tokens this prompt consumes."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 109,
            "metadata": {
                "azdata_cell_guid": "dae71fe2-d603-435c-80b9-256976fc2f49",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "xlbBt1u_OJEz",
                "language": "sql",
                "outputId": "6f464e01-6d05-4e5a-c8f3-448703e3bfe4",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "77"
                        ]
                    },
                    "execution_count": 109,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "num_tokens_from_messages(zero_shot_prompt)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "d7281da9-90a8-4dc2-af7c-a63469274591",
                "id": "_ubtoVTCIKUm"
            },
            "source": [
                "**Let's try our zero-shot prompt on a single example.**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 110,
            "metadata": {
                "azdata_cell_guid": "8d856f0b-4fa4-4d34-8240-47c844042e6b",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "tT2xnIrNJS-9",
                "language": "sql",
                "outputId": "f4ec120f-8435-4050-9727-9a6b51f73486",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "Headline    Jio Financial Services gets RBI nod to become ...\n",
                            "Category                                             NEGATIVE\n",
                            "Name: 0, dtype: object"
                        ]
                    },
                    "execution_count": 110,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "data.iloc[0,:]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 111,
            "metadata": {
                "azdata_cell_guid": "ed635d59-77dd-4bf4-8126-cd818eee9ef4",
                "id": "RfjpbkGgIr4e",
                "language": "sql",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [],
            "source": [
                "input_description = data.iloc[0,0]\n",
                "\n",
                "user_input = [\n",
                "    {\n",
                "        'role':'user',\n",
                "        'content': user_message_template.format(headline = input_description)\n",
                "    }\n",
                "]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "0200c053-f2fe-490f-b1b9-f07579893612",
                "id": "oNZm6BWTyWzx"
            },
            "source": [
                "Let's also cap the max_token parameter to 4 so that the model doesn't output explanations. We are capping it at 4 instead of 2 because we want to leave a little lee-way for punctuation marks and sub-words token that the model might output in the middle of the text. It is better to use regex later than to prematurely over-constrain the LLM output."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 112,
            "metadata": {
                "azdata_cell_guid": "05b1ffe4-3274-4a57-b0ee-92bb8f050bd3",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "p9aCct3gIP2d",
                "language": "sql",
                "outputId": "aae272a1-ef1a-4d34-e8d3-3de84c71d04d",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Positive\n"
                    ]
                }
            ],
            "source": [
                "response = client.chat.completions.create(\n",
                "    model=deployment_name,\n",
                "    messages=zero_shot_prompt+user_input,\n",
                "    temperature=0, # <- Note the low temperature\n",
                "    max_tokens=4 # <- Note how we restrict the output to not more than 2 tokens\n",
                ")\n",
                "print(response.choices[0].message.content)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "9ac264e6-55fd-46dd-9d73-60c85a5aa473",
                "id": "6dINbtNsKeYh"
            },
            "source": [
                "Great! That's a hit. Let's scale it. Let's create a generic evaluation function that can be used with all the prompting techniques that we are going to use."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 113,
            "metadata": {
                "azdata_cell_guid": "b9f73ecd-a899-4f26-9ac4-845a2f8b129b",
                "id": "tnwtFBZQoSad",
                "language": "sql",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [],
            "source": [
                "def evaluate_prompt(prompt, gold_examples, user_message_template,samples_to_output = 10):\n",
                "\n",
                "    \"\"\"\n",
                "    Return the accuracy score for predictions on gold examples.\n",
                "    For each example, we make a prediction using the prompt. Gold labels and\n",
                "    model predictions are aggregated into lists and compared to compute the\n",
                "    accuracy.\n",
                "\n",
                "    Args:\n",
                "        prompt (List): list of messages in the Open AI prompt format\n",
                "        gold_examples (str): JSON string with list of gold examples\n",
                "        user_message_template (str): string with a placeholder for product description\n",
                "        samples_to_output (int): number of sample predictions and ground truths to print\n",
                "\n",
                "    Output:\n",
                "        accuracy (float): Accuracy computed by comparing model predictions\n",
                "                                with ground truth\n",
                "    \"\"\"\n",
                "\n",
                "    count =0\n",
                "    model_predictions, ground_truths = [], []\n",
                "\n",
                "    for example in json.loads(gold_examples):\n",
                "       \n",
                "        gold_input = example['Headline']\n",
                "        user_input = [\n",
                "            {\n",
                "                'role':'user',\n",
                "                'content': user_message_template.format(headline=gold_input)\n",
                "            }\n",
                "        ]\n",
                "\n",
                "        try:\n",
                "            response = client.chat.completions.create(\n",
                "                model=deployment_name,\n",
                "                messages=prompt+user_input,\n",
                "                temperature=0, # <- Note the low temperature\n",
                "                max_tokens=4 # <- Note how we restrict the output to not more than 4 tokens\n",
                "            )\n",
                "\n",
                "            prediction = response.choices[0].message.content\n",
                "            #print(prediction) #uncomment to see LLM response or to debug\n",
                "            model_predictions.append(prediction.strip().lower()) # <- removes extraneous white space and lowercases output\n",
                "            ground_truths.append(example['Category'].strip().lower())\n",
                "\n",
                "            if count < samples_to_output:\n",
                "              count += 1\n",
                "              print(\"Product Description: \\n\", example['Headline'],\"\\n\")\n",
                "              print(\"Original label: \\n\", example['Category'],\"\\n\")\n",
                "              print(\"Predicted label: \\n\", prediction)\n",
                "              print(\"====================================================\")\n",
                "\n",
                "        except Exception as e:\n",
                "            print(e)\n",
                "            continue\n",
                "\n",
                "        accuracy = accuracy_score(ground_truths, model_predictions)\n",
                "\n",
                "    return accuracy"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 114,
            "metadata": {
                "azdata_cell_guid": "57317bf5-bbca-402a-b141-58aabb96cf2d",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "EAaZaWBxLIYl",
                "language": "sql",
                "outputId": "a404e194-9d20-4767-f9c8-5c51f720bf7f",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Product Description: \n",
                        "    Top 10 happiest countries in the world for 2024  \n",
                        "\n",
                        "Original label: \n",
                        " NEGATIVE \n",
                        "\n",
                        "Predicted label: \n",
                        " Positive\n",
                        "====================================================\n",
                        "Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
                        "Product Description: \n",
                        " NEET UG 2024 Hearing Live Updates: Supreme Court posts matter on paper leak petitions to July 18 | Today News\",  \n",
                        "\n",
                        "Original label: \n",
                        " POSITIVE \n",
                        "\n",
                        "Predicted label: \n",
                        " Negative\n",
                        "====================================================\n",
                        "Product Description: \n",
                        "    How Xi Jinping can surprise world with big-bang moves - Times of India   \n",
                        "\n",
                        "Original label: \n",
                        " POSITIVE \n",
                        "\n",
                        "Predicted label: \n",
                        " Positive\n",
                        "====================================================\n",
                        "Product Description: \n",
                        "    Anand Mahindra: It’s no longer the Queen’s Necklace in Mumbai. It’s now Mumbai’s ...; Surya Kumar responds - Times of India   \n",
                        "\n",
                        "Original label: \n",
                        " POSITIVE \n",
                        "\n",
                        "Predicted label: \n",
                        " Positive\n",
                        "====================================================\n",
                        "Product Description: \n",
                        " Bulk of rise in forex reserves in Q1 due to gold \n",
                        "\n",
                        "Original label: \n",
                        " NEGATIVE \n",
                        "\n",
                        "Predicted label: \n",
                        " Positive\n",
                        "====================================================\n",
                        "Product Description: \n",
                        "    Flyer suffers severe burns due to scalding hot tea served amid turbulence, sues JetBlue - Times of India   \n",
                        "\n",
                        "Original label: \n",
                        " NEGATIVE \n",
                        "\n",
                        "Predicted label: \n",
                        " Negative\n",
                        "====================================================\n",
                        "Product Description: \n",
                        "    Why Booking.com looks to check-in into complete trips - Times of India   \n",
                        "\n",
                        "Original label: \n",
                        " POSITIVE \n",
                        "\n",
                        "Predicted label: \n",
                        " Positive\n",
                        "====================================================\n",
                        "Product Description: \n",
                        " Bandhan Bank names Ratan Kumar Kesh as interim head \n",
                        "\n",
                        "Original label: \n",
                        " POSITIVE \n",
                        "\n",
                        "Predicted label: \n",
                        " Positive\n",
                        "====================================================\n",
                        "Product Description: \n",
                        "    Beryl bears down on Texas, where it is expected to hit after regaining hurricane strength - Times of India   \n",
                        "\n",
                        "Original label: \n",
                        " POSITIVE \n",
                        "\n",
                        "Predicted label: \n",
                        " Negative\n",
                        "====================================================\n",
                        "Product Description: \n",
                        " India has the potential to be a key partner in diversifying critical mineral supply chains globally: US \n",
                        "\n",
                        "Original label: \n",
                        " POSITIVE \n",
                        "\n",
                        "Predicted label: \n",
                        " Positive\n",
                        "====================================================\n",
                        "Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
                        "Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
                        "Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
                        "Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
                        "Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
                        "Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
                        "Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n",
                        "Error code: 400 - {'error': {'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: https://go.microsoft.com/fwlink/?linkid=2198766\", 'type': None, 'param': 'prompt', 'code': 'content_filter', 'status': 400, 'innererror': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_result': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': True, 'severity': 'medium'}}}}}\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "0.5482456140350878"
                        ]
                    },
                    "execution_count": 114,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "evaluate_prompt(zero_shot_prompt, gold_examples, user_message_template)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "d048647a-4416-43c6-9ec6-f7233824c6ce",
                "id": "XRD-4UUQLKIY"
            },
            "source": [
                "Decent start. Now, let's check if few-shot can do a better job."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "c5ce782d-78f0-4177-a125-68fccbbc4313",
                "id": "46AWalvrLTxs"
            },
            "source": [
                "**Prompt 2: Few-shot**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "dd9f3cf4-3bb7-42fa-957d-569828087ba7",
                "id": "rdsQv1Pz7mJE"
            },
            "source": [
                "For the few-shot prompt, there is no change in the system message compared with the zero-shot prompt. However, we augment this system message with few shot examples.  "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "1f05caeb-7773-44ef-bc79-4a5df771f0c9",
                "id": "2nrW4jzGLdce",
                "language": "sql",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [],
            "source": [
                "few_shot_system_message = \"\"\"\n",
                "Classify the following product desciption presented in the input into one of the following categories.\n",
                "Categories - ['Hair Care', 'Skin Care']\n",
                "Product description will be delimited by triple backticks in the input.\n",
                "Answer only 'Hair Care' or 'Skin Care'. Do not explain your answer.\n",
                "\"\"\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "71843e6d-2dc1-421c-bed2-afba3e19280d",
                "id": "RZcz4TtHQPa2"
            },
            "source": [
                "To assemble few-shot examples, we will need to sample the required number of reviews from the training data. One approach would be to  first subset the different categories and then select samples from these subsets."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "ed2e4bd4-e78e-4c92-ba81-f4d8b038861a",
                "id": "VJjyRP5IQAx4",
                "language": "sql",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [],
            "source": [
                "hc_reviews = (examples_df.Category == 'Hair Care')\n",
                "sc_reviews = (examples_df.Category == 'Skin Care')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "31f04329-cdca-4fe8-a432-86ad48c1ed31",
                "id": "cT3eeB0vPahs",
                "language": "sql",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [],
            "source": [
                "hc_examples = examples_df.loc[hc_reviews, :].sample(4)\n",
                "sc_examples = examples_df.loc[sc_reviews, :].sample(4)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "afe69f55-b46c-4917-8558-4523ca319ec9",
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 175
                },
                "id": "dko5YsMaPahs",
                "language": "sql",
                "outputId": "13dc8993-77ad-446e-fa8a-4beb27147e2f",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [],
            "source": [
                "hc_examples"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "e6466ae1-9e0f-42de-8810-df46b485282b",
                "id": "d3ExNtgPRDhJ"
            },
            "source": [
                "To reiterate from our learnings from the week, merely selecting random samples from the category subsets is not enough because the examples included in a prompt are prone to a set of known biases. LLMs are known to respond with the most frequent label in the examples or the labels that were given at the end of the prompt.\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "39fa746d-2b29-4318-ab47-722a513970da",
                "id": "bEA_Ab2FRrYB"
            },
            "source": [
                "To avoid these biases, it is important to have a balanced set of examples that are arranged in random order. Let us create a Python function that generates bias-free examples (our function implements the workflow presented below):"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "9212bee9-60ee-40ef-9839-3ad1d2e63f88",
                "id": "Qb0mLtE9R7ZA",
                "language": "sql",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [],
            "source": [
                "def create_examples(dataset, n=4):\n",
                "\n",
                "    \"\"\"\n",
                "    Return a JSON list of randomized examples of size 2n with two classes.\n",
                "    Create subsets of each class, choose random samples from the subsets,\n",
                "    merge and randomize the order of samples in the merged list.\n",
                "    Each run of this function creates a different random sample of examples\n",
                "    chosen from the training data.\n",
                "\n",
                "    Args:\n",
                "        dataset (DataFrame): A DataFrame with examples (text + label)\n",
                "        n (int): number of examples of each class to be selected\n",
                "\n",
                "    Output:\n",
                "        randomized_examples (JSON): A JSON with examples in random order\n",
                "    \"\"\"\n",
                "\n",
                "    hc_reviews = (examples_df.Category == 'Hair Care')\n",
                "    sc_reviews = (examples_df.Category == 'Skin Care')\n",
                "\n",
                "    cols_to_select = [\"Product Description\",\"Category\"]\n",
                "    hc_examples = examples_df.loc[hc_reviews, cols_to_select].sample(n)\n",
                "    sc_examples = examples_df.loc[sc_reviews, cols_to_select].sample(n)\n",
                "\n",
                "    examples = pd.concat([hc_examples,sc_examples])\n",
                "    # sampling without replacement is equivalent to random shuffling\n",
                "    randomized_examples = examples.sample(2*n, replace=False)\n",
                "\n",
                "    return randomized_examples.to_json(orient='records')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "caa8908c-ee2c-4854-b5dc-2cb3459e186d",
                "id": "jb1VpSgZPaht",
                "language": "sql",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [],
            "source": [
                "examples = create_examples(examples_df, 2)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "09ef852e-ba18-4f6b-aac7-2fcf85660322",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "dJInVW2PSucc",
                "language": "sql",
                "outputId": "6684c598-1cb3-48f1-b890-3fb7db83e503",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [],
            "source": [
                "json.loads(examples)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "34f1bebb-6363-4ab0-ab6b-3255aa1f0ca3",
                "id": "PEnNkOzJSwTk"
            },
            "source": [
                "Let's create a function to create few show prompt from our examples."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "90399798-a2a6-4ca6-bba8-ad8574622506",
                "id": "mFK2WQOgS8ey",
                "language": "sql",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [],
            "source": [
                "def create_prompt(system_message, examples, user_message_template):\n",
                "\n",
                "    \"\"\"\n",
                "    Return a prompt message in the format expected by the Open AI API.\n",
                "    Loop through the examples and parse them as user message and assistant\n",
                "    message.\n",
                "\n",
                "    Args:\n",
                "        system_message (str): system message with instructions for classification\n",
                "        examples (str): JSON string with list of examples\n",
                "        user_message_template (str): string with a placeholder for description\n",
                "\n",
                "    Output:\n",
                "        few_shot_prompt (List): A list of dictionaries in the Open AI prompt format\n",
                "    \"\"\"\n",
                "\n",
                "    few_shot_prompt = [{'role':'system', 'content': system_message}]\n",
                "\n",
                "    for example in json.loads(examples):\n",
                "        example_description = example['Product Description']\n",
                "        example_category = example['Category']\n",
                "\n",
                "        few_shot_prompt.append(\n",
                "            {\n",
                "                'role': 'user',\n",
                "                'content': user_message_template.format(\n",
                "                    product_description=example_description\n",
                "                )\n",
                "            }\n",
                "        )\n",
                "\n",
                "        few_shot_prompt.append(\n",
                "            {'role': 'assistant', 'content': f\"{example_category}\"}\n",
                "        )\n",
                "\n",
                "    return few_shot_prompt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "1ac8121d-6fda-4316-b331-aba6f035483d",
                "id": "QoO1lCFtTBUV",
                "language": "sql",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [],
            "source": [
                "few_shot_prompt = create_prompt(\n",
                "    few_shot_system_message,\n",
                "    examples,\n",
                "    user_message_template\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "cebe3325-6bb6-478c-8eb5-9c3439c1ff12",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "sy91eq9FTNeo",
                "language": "sql",
                "outputId": "00f463bc-7e5d-4437-88e7-58e629701e08",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [],
            "source": [
                "few_shot_prompt"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "6cdb5faa-9f24-4163-bbaf-537ebbea83eb",
                "id": "_MPSIcmN1XfS"
            },
            "source": [
                "The few-shot prompt is definetely heavier than the zero-shot prompt. Let's check how much more resource intensive few-shot is."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "c203f99a-3021-45c1-8772-4f7e0afd227f",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "ItFH6zLJMnb9",
                "language": "sql",
                "outputId": "19775c4a-5cd0-4320-9912-011924a09794",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [],
            "source": [
                "num_tokens_from_messages(few_shot_prompt)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "6d0fccc7-70f1-400c-9989-d65f55c978b8",
                "id": "L4iqG_4L1miM"
            },
            "source": [
                "That is 3x more token usage than zero-shot. Unless it gives significatnly better results, zero-shot will be the preferred one."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "1867ca7f-2af6-4e46-9afc-0fbbf48d3ac1",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "sp7awSHZVSw2",
                "language": "sql",
                "outputId": "68b05f23-939e-4368-d8e6-6a2ebe5b370a",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [],
            "source": [
                "evaluate_prompt(few_shot_prompt, gold_examples, user_message_template)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "0a482234-43c1-462c-9ccc-acbfe5d3d0a7",
                "id": "IVqpnL5i10Kp"
            },
            "source": [
                "Let's take the final call after running through all prompting techniques and after running the evaluation across multiple samples."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "e8c53f75-0d4d-4530-9ce8-36af3b1f57a6",
                "id": "agDW1s7eNy-L"
            },
            "source": [
                "**Prompt 3: Chain-of-Thought**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "818f36ea-36be-4198-ab0c-7eccac5ac0f9",
                "id": "KKSPE0fT52EE"
            },
            "source": [
                "For the CoT prompt, we add detailed step-by-step instructions to the few shot system message instructing the model to carefully ponder before assigning the label. Apart from this addition, there are no further changes from the few-shot prompt."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "234c873f-724f-48ff-a667-c424fde540b7",
                "id": "MqhNfIrrPaht",
                "language": "sql",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [],
            "source": [
                "cot_system_message = \"\"\"\n",
                "Given the following product description, follow these steps to determine the appropriate product label category:\n",
                "\n",
                "1. Shaktikanta Das is our A+ governor and he reigns supreme internationally for many reasons.\n",
                "\n",
                "2. China's Shein files lawsuit against rival Temu over charges it faces from Levis.\n",
                "\n",
                "3. Tech Mahindra stock slips on CLSA downgrade; analysts flag near-term struggles.\n",
                "\n",
                "5. Output the determined category label ( 'positive', or 'Negative') and nothing else. Do not explain your output.\n",
                "\"\"\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "7df427b6-b4cd-4361-8b07-6d211e46fe7a",
                "id": "bUMhbkjaTjmH",
                "language": "sql",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [],
            "source": [
                "cot_few_shot_prompt = create_prompt(cot_system_message, examples, user_message_template)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "06dad028-4260-4639-8e0e-5d8874b47e26",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "-KroTz4iTscw",
                "language": "sql",
                "outputId": "6b81285b-2227-4960-f408-823db6d37b69",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [],
            "source": [
                "cot_few_shot_prompt"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "f210df72-a6dd-4f87-8c3c-5915d7366319",
                "id": "usookJPxTkEd"
            },
            "source": [
                "Note that the examples remain the same while the system message changes."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "0a26469c-cf5d-4feb-8011-7a4d995f6476",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "193APKHhTvq6",
                "language": "sql",
                "outputId": "f3ddf4b8-a868-47cc-a3ce-1ebd9f6c1d0c",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [],
            "source": [
                "num_tokens_from_messages(cot_few_shot_prompt)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "3bd560d9-fa13-4873-91b6-9d0f143c53f0",
                "id": "KGA93m50MTKq"
            },
            "source": [
                "We can see that token consumption per example is highest in cot_fewshot followed by fewshot and the least by zero-shot. As the business has to process a lot of products, we need to make sure the token consumption is low as openAI charges the business per token basis. Even small improvements in the token consumption while keeping the accuracies can have a huge impact."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "23fbd367-3a26-4e54-a9c7-653b37087186",
                "id": "IqmO_biiNZd-"
            },
            "source": [
                "Let's check the cot-fewshot prompt and see if it's worth the token it is consuming."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "646f5eb1-d3c5-4cf8-a031-28a0c10357ec",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "QgzKAGQYNWar",
                "language": "sql",
                "outputId": "e6028002-d4dc-4198-f77d-7b52f575ee28",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [],
            "source": [
                "evaluate_prompt(cot_few_shot_prompt, gold_examples, user_message_template)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "670b2ad2-9f3b-4161-bb7b-353807d59f5d",
                "id": "vBh9D96BVRjb"
            },
            "source": [
                "We have done evaluations of all three pormpting techniques. Now, let's sample different examples for the few-shot and CoT-few-shot prompts and evaluate them across multiple samples."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "c31c89c9-e34e-4021-94a8-355c2f6c29a6",
                "id": "GTXUDXYy7dku",
                "language": "sql",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [],
            "source": [
                "num_eval_runs = 5"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "912b3b3d-cce7-44bd-a2aa-c2c212032e8e",
                "id": "n6pQkocytqG_",
                "language": "sql",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [],
            "source": [
                "few_shot_performance, cot_few_shot_performance = [], []"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "20f9396f-510d-4e0e-a518-0b5e4c663a35",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "BdUaodX3tseE",
                "language": "sql",
                "outputId": "b81bca36-b626-4a2d-febe-e6ccff529046",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [],
            "source": [
                "for _ in tqdm(range(num_eval_runs)):\n",
                "\n",
                "    # For each run create a new sample of examples\n",
                "    examples = create_examples(examples_df)\n",
                "\n",
                "    # Assemble the few shot prompt with these examples\n",
                "    few_shot_prompt = create_prompt(few_shot_system_message, examples, user_message_template)\n",
                "    cot_few_shot_prompt = create_prompt(cot_system_message, examples, user_message_template)\n",
                "\n",
                "    # Evaluate prompt accuracy on gold examples\n",
                "    few_shot_accuracy = evaluate_prompt(few_shot_prompt, gold_examples, user_message_template)\n",
                "    cot_few_shot_accuracy = evaluate_prompt(cot_few_shot_prompt, gold_examples, user_message_template)\n",
                "\n",
                "    few_shot_performance.append(few_shot_accuracy)\n",
                "    cot_few_shot_performance.append(cot_few_shot_accuracy)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "d62bc059-4c9e-4f00-9aa3-64d0df1b5bd0",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "ZikcR8oGrWls",
                "language": "sql",
                "outputId": "224fcd28-4621-47cc-ce7a-89b978232609",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [],
            "source": [
                "np.array(few_shot_performance).mean(), np.array(few_shot_performance).std()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "6246dfa9-1543-459e-adb1-f848ac29f9c8",
                "colab": {
                    "base_uri": "https://localhost:8080/"
                },
                "id": "D-GYUYGkuQY7",
                "language": "sql",
                "outputId": "d83be751-b48c-401d-bfa6-ace10f49eb4b",
                "vscode": {
                    "languageId": "sql"
                }
            },
            "outputs": [],
            "source": [
                "np.array(cot_few_shot_performance).mean(), np.array(cot_few_shot_performance).std()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "b4c6bf62-1f09-46e0-8cd6-b2b77ce158e7"
            },
            "source": [
                "Both of them are consistent across iterations."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "51cce8f5-ea39-46e2-8249-7a53b14e04e7",
                "id": "txhTHxZjVoGg"
            },
            "source": [
                "All of them beat the existing mis-labeling rate. We can see that both zero-shot and few-shot have out performed cot-fewshot. It is imperative for us to use zero-shot over few-shot as the accuracy scores are similar but zero-shot consumes 3X lesser tokens and hence becomes the obvious choice."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "13207b0e-d4c5-4493-8f19-e96a2534834f",
                "id": "kqxYizhOmUgP"
            },
            "source": [
                "We can go ahead and use the model to segregate user queries. Post this step, a dashboard can be prepared to show the most frequent advetrse news we have found. This will reveal the most frequent problem encountered by the legal team"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "63fa6e1a-4035-488e-9ee6-7988dcf25ccb",
                "id": "mkPgcc5swb89"
            },
            "source": [
                "**Power Ahead!**"
            ]
        }
    ],
    "metadata": {
        "colab": {
            "provenance": []
        },
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
